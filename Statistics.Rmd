---
title: "Capstone Project for Introduction to Data Science"
author: "Charmayne Patterson"
date: "8/7/2019"
output:
  md_document:
    variant: markdown_github
---

## Introduction
Throughout history, African Americans have faced numerous limitations and restrictions to their rights as Americans. The institution of slavery proved a crucial impediment to not only their freedom, but also their achievement. As a result of chattel slavery, African Americans were denied the most basic of rights and opportunities.

Historical myths would have us believe that the American north was synonymous with freedom and that once there, African Americans experienced full freedom and inclusion within American society. In fact, we know that life in the north presented its own challenges for African Americans and the lives they sought to create for themselves. I have attempted to use data science to better help capture and illustrate the  

Census data from Philadelphia will provide the basis for our evaluation and prediction.  In 1847, the United States had not yet confronted the institution of slavery or its consequences. At that point, almost 20 years before the start of the American Civil War, northern states of the relatively new republic had only recently freed those enslaved within their borders. Northern cities like Philadelphia, PA were regarded as havens for fugitive slaves and places were Blacks could live and actually experience freedom. 

The data set helps us to gain insights into the lives of Black Philadelphians at the time. It includes census information concerning family size, the numbers of males and females residing in a household, their occupations, whether or not they were born in the state or not, whether or not they were born into slavery or not, and their ability to read and/or write.          


In order to explore the potential relationships between several variables related to the status of African Americans in Philadeplhia in 1847,we must start off by reading the census data.    


```{r, warning=FALSE, message=FALSE}
library(tidyverse) #The swiss knife!
library(caret)
```


Now that the packages  are loaded,  we can get the data into R. 

```{r}
census <- read.csv("census3.csv")
```

## Exploratory Data Analysis

Now that we have ingested the data, let us start exploring it. The first thing to do is to have a quick look at our data. For that, we can use the `str()` function or the more human readable (and intuitive), `glimpse()` function.

```{r}
glimpse(census)
```

Now we can begin exploring the data. The first thing to do is to have a quick look at it, noticing that there are 2851 rows in our dataset with 11 variables. It added the `X1` variable on its own while importing the data. Not only can we see the variables, but we also now know the type of variables, for example, `Male Occupation` is a characteer variable. Should it be a factor?based on the numerous observations and 11 variables, it is obvious that the data must be cleaned in order to make it more manageable and readable. 



While carrying out any analysis, it is always best to start off with a question. It is also important to know the metadata, or the data that describes the data. For example, we see the variable `Can.read` has values ranging from 0 to 5 (we will of course check this), but have no idea what these values mean. We may have assumed that this might be a binary value with 0 indicating the person cannot read and 1 indicating that the person can read. Or this could also mean the total number of people in a household who can read (that sounds more plausible to me). Either way, we will look at the metadata or a data dictionary, if one exists. we can also observe the different values available in the `Can.read` and `Can.write` variables.

```{r}
table(census$Can.read)
table(census$Can.write)
```
Looking at this, we are now more inclined to think that these two variables show us the number of people who can read or write in a family. So with these assumptions, what are the questions that come to mind? Personally I would really like to understand the impact of proffessions, gender and other variables available, on the  level of education. For the 'level of education' we have two variables available, viz. `Can.read` and `Can.write`. we also know the size of a family. So perhaps it would be best to divide these two variables with the size of the family and look at this as a percentage to say what percent of a family is well versed with reading or writing. Prior to that we also want to check for discrepancies in the dataset. Given the family size, the sum of the Males and Females should be equal to the family size, considering this era only provided binary options for gender. 


```{r}
#Create a new variable called GenderSum and then look at the difference
census <- census %>% mutate(
  GenderSum = Males + Females,
  FamDiff = `Family.Size` - GenderSum
)

which(census$FamDiff > 0)
```

There are about 21 values that don't quite match up. Row 71 provides an example. While it says that the family size is 5, it has only 1 male and 2 females. This doesn't quite add up. So maybe removing these values and the two additional columns we created, as well as the `X1` column.



```{r}
census <- census %>% filter(FamDiff == 0) %>% select( -GenderSum, -FamDiff)
```

Now we can mutate a new variable based on the percentages discussed above.

```{r}
census <- census %>% mutate(
  Read = round((Can.read/`Family.Size`)* 100, 2),
  Write = round((Can.write/`Family.Size`)* 100, 2)
)
```


We could also perhaps combine these two newly created variables and have one cummulative variable which is just the mean of these two, to signify the overall education level. After creating this new variable we won't need the original variables.


```{r}
census <- census %>% mutate(
  EduLevel = round((Read + Write)/2, 2) 
) 
```

We must also check and see that our `EduLevel` is not greater that 100%.

```{r}
which(census$EduLevel > 100)
```


Looking at row 144, we see that the family size is 3, but the number of people who can read or write is 6 and 4 respectively. This alerts me to the fact that something is wrong here. We will need to filter for only those values that are less than or equal to 100.

```{r}
census <- census %>% filter(EduLevel <= 100) %>% select(-(Can.read:Write))
```

Ok, so far so good. Now we must address the task of making some sense of the male and female occupations. There are too many occupations and so they need to be reduced. The remainder of this analysis focuses on education level, literacy, and occupations.  The data frame (census_glm.csv) below includes a variable labeled literate.  If a family has above a 50% education level, then the family is literate.  A (1) in the literate column specifies that a family is literate and a (0) means that the family is not literate.    


```{r}
census_glm<- read.csv("census_glm.csv")
```

Additional variables are included in the data file.  These variables are removed using the code that follows.

```{r}
census_glm<-select(census_glm, -c(X.1, X))
```

Using plots and graphs, we explore the data with these nine questions in mind.These questions can help us to think about the data.

1. What was the most common profession for males? 
2. Waht was the most common profession for females? 
3. How do these professions measure up when viewed from the education level? 
4. Which is the least educated profession? 
5. Which is the most educated profession? 
6. Is there a relationship between family size and Education Level? 
7. Is there any diï¬€erence between genders as far as education level is concerned? 
8. Does being born a slave have any bearing on the education level? 




```{r}
census_glm %>% group_by(Male.Occupation) %>% count() %>% arrange(desc(n))
census_glm %>% group_by(Female.Occupation) %>% count() %>% arrange(desc(n))
```

The occupation with the largest number of males is porter. Since there are 1,426 different occupations, a filter is created to include only occupations that have at least 20 male family members.  When viewing the occupations for females, it seems that more females seem to hold a position than males.  This observation was fascinating to me as the male in modern times is viewed as the family provider.  The most popular female position held is a washer.  There are 392 women washers in the data set. Since there are 796 different occupations, a filter is created to include only occupations that have at least 20 female family members.The results are printed to the consoloe.





```{r}
male.occ_count <- census_glm %>% group_by(Male.Occupation) %>% count() %>% filter(n > 19) %>% arrange(desc(n))
female.occ_count <- census_glm %>% group_by(Female.Occupation) %>% count() %>% filter(n > 19) %>% arrange(desc(n))
male.occ_count
female.occ_count

```


This filter seems to be a good one. Now we can take a deeper dive into the data to determine education level by occupation. A comparison among occupations answers question 1. The results will be displayed as a bar graph.

```{r}
ggplot(census_glm %>% filter(Male.Occupation %in% unique(male.occ_count$Male.Occupation)),
       aes(x = Literate, fill = Male.Occupation)) + geom_bar(position = 'dodge')

ggplot(census_glm %>% filter(Female.Occupation %in% unique(female.occ_count$Female.Occupation)),
       aes(x = Literate, fill = Female.Occupation)) + geom_bar(position = 'dodge')
```


Of the 14 chosen male occupations, families that have male porters have the highest illiteracy level.  If a family has a male waiter, then the family is more likely to be literate.  Females that hold a position washing and ironing have the least educated families.  However, families that have female washers have higher family literacy levels.


Attention is shifting to determining a relationship between the variables.   We observe the relationship between family size and education level.  A color scheme is used to distinguish between the literate and non-literate groups easily.


```{r}
ggplot(census_glm, aes(x = EduLevel, y = Family.Size, color=Literate)) +

  geom_point() + geom_jitter()
```


An interesting relationship between the variables is recognized.  The relationship seems to be parabolic.


```{r}
ggplot(census_glm, aes(x = EduLevel, y = Females, color=Literate)) +

  geom_point() + geom_jitter()

ggplot(census_glm, aes(x = EduLevel, y = Males, color=Literate)) +

  geom_point() + geom_jitter()
```








```{r}
ggplot(census_glm, aes(x = Born.slaves, y = EduLevel, color=Literate)) +

  geom_point() + geom_jitter()
```


Considering question number 8, we draw a table to capture information to answer the question and to confirm the results from the graph above.

```{r}
census_glm %>% group_by(Literate, Born.slaves) %>% count() 

```


Out of 2242 study participants, 1710 were born slaves and are in a household that is deemed to be illiterate while 514 of the participants that were taken as slaves have literate families.  Occupation is discussed next.

## Machine Learning 

In this section, we are only going to focus on the top five occupations for females and males as there are too many occupations and the model may not converge.  The top means the occupations with the largerest n.  A new dataframe with filters is created.


```{r}
census_glm<- read.csv("census_glm.csv")
df <- census_glm %>% filter( 
  Female.Occupation %in% female.occ_count$Female.Occupation[1:5],
Male.Occupation %in% male.occ_count$Male.Occupation[1:5]) 
df
  
```


The filter above reduces the data frame to only 170 observations.  Therefore, a new filter is created below.


```{r}
df_1 <- census_glm %>% filter( 
  Female.Occupation %in% female.occ_count$Female.Occupation[1:7],
Male.Occupation %in% male.occ_count$Male.Occupation[1:7]) 
df_1
  
```



For the predictive part of this project, I'd like to predict if a family is literate given family size, male occupation, female occupation, and whether the family members were born slaves.  Based on the variables of prediction, the problem is framed as a logistic regression whether a family is literate (1) or not(0).   Notice that there are 27.3 familes that are literate in the filtered data frame.  This may cause problems when running a predictive model.

```{r}
lit_count <- df %>% group_by(Literate) %>% count()
lit_count

lit_count <- df_1 %>% group_by(Literate) %>% count()
lit_count
```


Let's move on with creating the model.  The independent variables for the model are family size, male occupation, female occupation, and whether the family members were born slaves.  These variables are selected intuitively as variables that can give information regarding the dependent variable, literate.  

```{r}
glimpse(df)
glimpse(df_1)
```

The output and independent variables are integers but should be factors. The lapply function is used to convert this variable to a factor variables.

```{r}
names <- c(3,12)
df[,names] <- lapply(df[,names] , factor)
glimpse(df_1)

names <- c(3,12)
df_1[,names] <- lapply(df_1[,names] , factor)
glimpse(df_1)
```

Prior to building the model lets split the dataset into two: training and test data. Typically a 80:20 split is what is used. So we will train our model on 80% and then test it on the remaining 20%. The `caret` package in R is the most used package for machine learning and contains helpful functions for ML tasks. The `createDataPartition()` function is utilized to achieve the split data set.  We split both data frames df and df_1.

```{r}
set.seed(7)
# create a list of 80% of the rows in the original dataset we can use for training
#validation_index <- createDataPartition(df$Literate, p=0.80, list=FALSE)
# select 20% of the data for validation
#testset <- df[-validation_index,]
# use the remaining 80% of data to training and testing the models
#trainset <- df [validation_index,]
```

```{r}
#set.seed(7)
# create a list of 80% of the rows in the original dataset we can use for training
#validation_index <- createDataPartition(df_1$Literate, p=0.80, list=FALSE)
# select 20% of the data for validation
#testset_1 <- df_1[-validation_index,]
# use the remaining 80% of data to training and testing the models
#trainset_1 <- df_1 [validation_index,]
```

```{r}
#write.csv(testset,"testset.csv")
#write.csv(testset_1, "testset_1.csv")
#write.csv(trainset,"trainset.csv")
#write.csv(trainset_1,"trainset_1.csv")
```
It is interesting to note that repeatedly running the syntax for the testing and training sets returned various results for the test set and train set data frames. Thus, the code is present but is removed from the code chunk. As an alternative, after running the code for splitting the data set, each data frame, testset, testset_1, trainset, and trainset_1 was written as a .csv file.This enabled consistency in the previously listed dataframes and models.
```{r}
testset<- read.csv("testset.csv")
testset_1<- read.csv("testset_1.csv")
trainset<- read.csv("trainset.csv")
trainset_1<- read.csv("trainset_1.csv")
```
 

## Model Fitting
Now let's use the `glm()` functionfor building the logistic model. We will run the model on both data frames to determine if the specific filtering gives a different result.

```{r}
model <- glm(`Literate` ~ Male.Occupation+Female.Occupation+Born.slaves+Family.Size, data = trainset, family = 'binomial')
summary(model)

```



```{r}
model_1 <- glm(`Literate` ~ Male.Occupation+Female.Occupation+Born.slaves+Family.Size, data = trainset_1, family = 'binomial')
summary(model_1)
```

Both models converged, we produced a summary for each model.  In "model" the statistically significant variables are male occupation laborer, male occupation porter, born slaves, and family size.  The variables that have any level of significance in "model_1" are male occupation carrier, male occupation laborer, male occupation porter, male occupation seaman, male occupation waiter, and family size.Included in the analysis are variables of any level of siginficance.  

The code below runs the test data through the model.

```{r}
testsetb <- testset[-c(11,14),] 
```

```{r}
testset_b <- testset_1[-c(11,20,32,37,31,24,21,18,16),] 
```

```{r}
testsetb$Predicted <- predict(model, newdata = testsetb, type = 'response')
```


```{r}
summary(testsetb$Predicted)
```

```{r}
testset_b$Predicted <- predict(model, newdata = testset_b, type = 'response')
```


```{r}
summary(testset_b$Predicted)
```

Note that for the model "model", we were able to run the model and the prediction.  However for the model "model_1", we were able to run the model but not the prediction function on the test data set.  This is because splitting the original data set into training and testing data caused "trainset_1" and "testset_1" to have different levels for "Male.Occupation".  Thus the analysis is continued using the testset data frame. Essentially, we took out "unusual variables" in the test data set, but not the training data set.

The results indicate that families containing a male with the occupation of carrier, laborer and porter are most likely to be literate. Also, smaller families are more likely to be literate.  


Next we set up a confusion matrix to look at our predictions.  This matrix will help to validate the model by determining if the predicted answers match up with the actual answers.  Now ideally speaking, if the value is greater than 0.5, we will say that the family is literate, otherwise the family is not literate. However, 0.5 is not always the most optimal cutoff. In R, there is a package called `InformationValue` which contains a function called `optimalCutoff()` whose job is to determine the optimal cutoff for a data set prediction. This package is used to  find the the optimal cutoff probability. 


```{r, message=FALSE, warning=FALSE}
library(InformationValue)
opt_cutoff <- optimalCutoff(testsetb$`Literate`, testsetb$Predicted)[1]
opt_cutoff
```
This turns out to be `r opt_cutoff`. 

```{r}
testsetb$Predicted <- ifelse(testsetb$Predicted >= opt_cutoff, 1, 0)
```

```{r}
testsetb %>% select(`Literate`, Predicted) %>% table()
```


From this matrix we see that there were 32 families predicted as not literate and they were actually not literate.  There were two faimiles predicted to be literate and were not actually literate.  In this matrix notice that the actual value "1" which signifies that a family is literate is not present.  This is because in the testing data set all families were not literate.This is a result of the small data set.

```{r, message=FALSE, warning=FALSE}
library(InformationValue)
opt_cutoff <- optimalCutoff(testset_b$`Literate`, testset_b$Predicted)[1]
opt_cutoff
```
This turns out to be `r opt_cutoff`. 

```{r}
testset_b$Predicted <- ifelse(testset_b$Predicted >= opt_cutoff, 1, 0)
```

```{r}
testset_b %>% select(`Literate`, Predicted) %>% table()
```


## Results
The results of the capstone project indicate that smaller families are more likely to be literate. They also suggest that male occupations are more likely to indicate a literate family than female occupatons. Addtionally (and most surprisingly) having a family member who was born a slave does not predict the literacy of these families.    

What does deviance residuals mean? 
The deviance residual is a measure used to determine if a model is a good fit. Higher numbers are indicators of a bad fit. The high deviance for both models (135.42 on 128  degrees of freedom and 166.07 on 153  degrees of freedom) suggest that these aren't good models for making predictions of literacy.  

What does AIC mean?
The Aikike Information Criterion (or AIC) for the two models were 153.42 and 190.07 respectively.
The smaller AIC for "model" as opposed to "model1" indicates that "model"" is a better predictive model. 

## Recommendations
These findings suggest that the occupations of family members have more of a bearing on litercay rates than the other variables including gender and being born in the state. 

Limitations in the census data presented challenges in identifying what variables would prove most impactful to literacy. This prject served as a good starting point for identifying the ways in which census data can be used to make predictions about historical phenomena.

## Future Work
As the census data is already collected and cannot be elaborated upon, this project provides a springboard to engage in similar data analysis for other cities and other eras. It would be interesting to determine, for exmaple,how the census data from 1847 compares to Philadeplia census data from a later period, perhaps after the American Civil War. It would also be interesting to compare Philadelphia's data to other cities, for example Boston or New York City.  



